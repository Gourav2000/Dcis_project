# -*- coding: utf-8 -*-
"""Modelling

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QvXikC1dvxcLgnJy2DSoOdH2SMhxI-pl
"""

import numpy as np
import scipy as sp
import skimage.io
import skimage.measure
import skimage.color
import shutil
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import *
import os
import zipfile
import shutil
import cv2
from PIL import Image, ImageOps
from tqdm.auto import tqdm
import tqdm
from imageio import *
from torchvision import *
import torchvision.transforms as transforms
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.feature import hog
from skimage import exposure
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(14,14)
dev='cpu'
if torch.cuda.is_available():
  dev='cuda'
print(dev)
dev=torch.device(dev)
plt.style.use('fivethirtyeight')


file = '../dcis/5_DCIS'
import os
import shutil
def change_intensity(image):
  image=np.copy(image)
  for i in range(image.shape[0]):
    for j in range(image.shape[1]):
      for k in range(3):
        if image[i][j][k]!=255:
          image[i][j][k]=0
  return image;

def resize_with_padding(img, expected_size, fill=0):
    img.thumbnail((expected_size[0], expected_size[1]))
    # print(img.size)
    delta_width = expected_size[0] - img.size[0]
    delta_height = expected_size[1] - img.size[1]
    pad_width = delta_width // 2
    pad_height = delta_height // 2
    padding = (
        pad_width,
        pad_height,
        delta_width - pad_width,
        delta_height - pad_height,
    )
    return ImageOps.expand(img, padding, fill=fill)

def remove_stroma(image):
    ar=np.array([255,0,255])
    arp=np.array([255,0,0])
    chan=np.array([255,255,255])
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
          if (image[i][j]==ar).all() or (image[i][j]==arp).all():
            image[i][j]=chan
    return image
def func_(img):
    filterG=cv2.getGaborKernel((39,39),1.0,90.0,7.5,1.0,1,ktype=cv2.CV_64F)
    gabrol_cell=cv2.filter2D(img,cv2.CV_8UC3,filterG)
    gabrol_cell=change_intensity(gabrol_cell)
    gabrol_ws=gabrol_cell.copy()
    gabrol_ws=remove_stroma(gabrol_ws)
    imgF=Image.fromarray(gabrol_ws)
    imgF = resize_with_padding(imgF, (1024, 1024), (255, 255, 255))
    gabrol_ws = np.asarray(imgF)
    gabrol_ws=change_intensity(gabrol_ws)
    return gabrol_ws

L=[]
cnt=0;
'''
for i in os.listdir('../dcis/5_DCIS'):
  if '.png' in i and  i.split('.')[1]!='png':
      continue
  if cnt>700:
      break

  L.append([os.path.join('../dcis/5_DCIS',i),0])
  cnt+=1
cnt=0
'''
for i in os.listdir('../normal/0_N'):
    if '.png' in i and i.split('.')[1]!='png':
        continue
    if cnt>700:
        break;
    L.append([os.path.join('../normal/0_N',i),1])
    cnt+=1

print(len(L))
class CreateDataset(Dataset):
    def __init__(self,path,transforms=None):
      self.path=path
      self.transforms=transforms
    def __len__(self):
      return self.path.__len__()
    def __getitem__(self,indx):
      img=imread(self.path[indx][0])
      img=func_(img)
      img=torch.tensor(img.reshape(3,1024,1024),dtype=torch.float32)
      if self.transforms:
        img=self.transforms(img)
      label=torch.tensor([self.path[indx][1]],dtype=torch.float32)
      return img,label
datas=CreateDataset(L,transforms=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.Normalize(mean=(0.32,0.31,0.39),std=(0.23,0.22,0.24))]))
traind,vald=torch.utils.data.dataset.random_split(datas,[int(len(datas)*0.2),len(datas)-int(len(datas)*0.2)])
Train=DataLoader(traind,shuffle=True,batch_size=4,drop_last=True)
Val=DataLoader(datas,shuffle=True,batch_size=4,drop_last=True)
import tqdm
#dev=torch.device('cuda')
model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Sequential(
    nn.Linear(num_ftrs, 128),
    nn.ReLU(inplace=True),
    nn.Linear(128,64),
    nn.ReLU(inplace=True),
    nn.Linear(64,1)
)
import sys
model_ft = model_ft.to(dev)
model_ft=torch.load('model.pt')
tmp1=None
tmp2=None
C=0
T=0
fp=0
fn=0
tp=0
tn=0
hh=tqdm.tqdm(Val,desc="Accuracy")
for x,y in hh:
    pred=torch.sigmoid(model_ft(x.to(dev)))
    for i in range(len(pred)):
        if pred[i][0]>=0.25:
            pred[i][0]=1
        else:
            pred[i][0]=0
        if int(pred[i][0])==int(y[i][0]):
            C+=1
            if int(y[i][0])==0:
                tn+=1
            else:
                tp+=1
        elif int(y[i][0])==0:
            fp+=1
        elif int(y[i][0])==1:
            fn+=1
        T+=1
    hh.set_postfix(Accuracy=C/T)
print(tp,fp,tn,fn)
print(C/T)
for x,y in Val:
    tmp1=y
    tmp2=x
    break;
pred=torch.sigmoid(model_ft(tmp2.to(dev)))
print(pred,tmp1)
sys.exit(0)
criterion = nn.BCEWithLogitsLoss()
torch.save(model_ft,'model.pt')
import torch.optim as optim
optimizer_ft = optim.Adam(model_ft.parameters(), lr=4.2e-5)
epochs=5
print('Started T')
for e in range(epochs):
  OP=0
  #H=0
  pbar=tqdm.tqdm(Train,desc="Training")
  for x,y in pbar:
    optimizer_ft.zero_grad()
    x,y=x.to(dev),y.to(dev)
    pred=model_ft(x)
    loss=criterion(pred,y)
    loss.backward()
    optimizer_ft.step()
    OP+=loss.item()
    checkpoint = {
    'epoch': e + 1,
    'state_dict': model_ft.state_dict(),
    'optimizer': optimizer_ft.state_dict()
   }
  pbar.set_postfix(TrainLoss=loss.item())
  torch.save(model_ft,'model.pt')
  print("Validating")
  H=0;
  for x,y in tqdm.tqdm(Val,desc="Training"):
      x,y=x.to(dev),y.to(dev)
      loss_p=criterion(model_ft(x),y)
      H+=loss_p.item()

  print(f"Epochs[{e+1}/{epochs}] TrainLoss: {OP/len(Train)} and ValLoss:{H/len(Val)}")
  with open("V.txt","w") as ff:
      ff.write(f"Epochs [{str(e+1)}] TrainLoss :{str(OP/len(Train))} and ValLoss:{str(H/len(Val))}\n")

