# -*- coding: utf-8 -*-
"""Modelling

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QvXikC1dvxcLgnJy2DSoOdH2SMhxI-pl
"""

import numpy as np
import scipy as sp
import skimage.io
import skimage.measure
import skimage.color
import shutil
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import *
import os
import zipfile
import shutil
import cv2
from PIL import Image, ImageOps
from tqdm.auto import tqdm
import tqdm
from imageio import *
from torchvision import *
import torchvision.transforms as transforms
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.feature import hog
from skimage import exposure
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize']=(14,14)
dev='cpu'
if torch.cuda.is_available():
  dev='cuda'
dev=torch.device(dev)
plt.style.use('fivethirtyeight')

from google.colab import drive
drive.mount('/content/drive')

!unzip /content/drive/MyDrive/5_DCIS_train.zip

file = '/content/5_DCIS'
import os
import shutil
for i in os.listdir(file):
  ok=i.split('.');
  if ok[1]!='png' or len(ok)>2:
    print(i)
    shutil.rmtree(os.path.join(file,i))

def change_intensity(image):
  image=np.copy(image)
  for i in range(image.shape[0]):
    for j in range(image.shape[1]):
      for k in range(3):
        if image[i][j][k]!=255:
          image[i][j][k]=0
  return image;

def resize_with_padding(img, expected_size, fill=0):
    img.thumbnail((expected_size[0], expected_size[1]))
    # print(img.size)
    delta_width = expected_size[0] - img.size[0]
    delta_height = expected_size[1] - img.size[1]
    pad_width = delta_width // 2
    pad_height = delta_height // 2
    padding = (
        pad_width,
        pad_height,
        delta_width - pad_width,
        delta_height - pad_height,
    )
    return ImageOps.expand(img, padding, fill=fill)

def remove_stroma(image):
    ar=np.array([255,0,255])
    arp=np.array([255,0,0])
    chan=np.array([255,255,255])
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
          if (image[i][j]==ar).all() or (image[i][j]==arp).all():
            image[i][j]=chan
    return image
def func_(img):
    filterG=cv2.getGaborKernel((39,39),1.0,90.0,7.5,1.0,1,ktype=cv2.CV_64F)
    gabrol_cell=cv2.filter2D(img,cv2.CV_8UC3,filterG)
    gabrol_cell=change_intensity(gabrol_cell)
    gabrol_ws=gabrol_cell.copy()
    gabrol_ws=remove_stroma(gabrol_ws)
    imgF=Image.fromarray(gabrol_ws)
    imgF = resize_with_padding(imgF, (1024, 1024), (255, 255, 255))
    gabrol_ws = np.asarray(imgF)
    gabrol_ws=change_intensity(gabrol_ws)
    return gabrol_ws

L=[]
cnt=0;
for i in os.listdir('/content/5_DCIS'):
  if cnt>10:
    break
  L.append([os.path.join('/content/5_DCIS',i),0])
  cnt+=1

class CreateDataset(Dataset):
    def __init__(self,path,transforms=None):
      self.path=path
      self.transforms=transforms
    def __len__(self):
      return self.path.__len__()
    def __getitem__(self,indx):
      img=func_(imread(self.path[indx][0]))
      img=torch.tensor(img.reshape(3,1024,1024),dtype=torch.float32)
      if self.transforms:
        img=self.transforms(img)
      label=torch.tensor([self.path[indx][1]],dtype=torch.float32)
      return img,label
datas=CreateDataset(L,transforms=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.Normalize(mean=(0.42,0.41,0.38),std=(0.23,0.22,0.24))]))
traind,vald=torch.utils.data.dataset.random_split(datas,[len(datas)*0.8,len(datas)-len(datas)*0.8)
Train=DataLoader(traind,shuffle=True,batch_size=2,drop_last=True)
Val=DataLoader(vald,shuffle=True,batch_size=2,drop_last=True)

for x,y in Train:
  print(x.shape,y.shape)
  break

import tqdm
dev=torch.device('cuda')
model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Sequential(
    nn.Linear(num_ftrs, 64),
    nn.ReLU(inplace=True),
    nn.Linear(64,1)
)


model_ft = model_ft.to(dev)

criterion = nn.BCEWithLogitsLoss()

import torch.optim as optim
optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-3)

epochs=10
for e in range(epochs):
  OP=0
  pbar=tqdm.tqdm(Train,desc="Training")
  for x,y in pbar:
    optimizer_ft.zero_grad()
    x,y=x.to(dev),y.to(dev)
    pred=model_ft(x)
    loss=criterion(pred,y)
    loss.backward()
    optimizer_ft.step()
    OP+=loss.item()
    checkpoint = {
    'epoch': e + 1,
    'state_dict': model_ft.state_dict(),
    'optimizer': optimizer_ft.state_dict()
    }
  if (e+1)%10==0:
    optimizer_ft.load_state_dict['lr']*=0.1;
  print(f"Epochs[{e+1}/{epochs}]Loss: {OP/x.shape[0]} Acc:")

model_ft

plt.imshow(func_(imread('/content/subham/BRACS_1476_DCIS_14.png')))

class Network(nn.Module):
  def __init__(self,shape=3):